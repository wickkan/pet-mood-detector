{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pet Mood Detector - Training Notebook\n",
    "\n",
    "This notebook demonstrates the training process for the Pet Mood Detector project. It allows you to:\n",
    "1. Load and explore the dataset\n",
    "2. Define and train the model\n",
    "3. Visualize training metrics\n",
    "4. Test the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms, datasets\n",
    "import time\n",
    "import copy\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Add parent directory to path so we can import our modules\n",
    "sys.path.append('..')\n",
    "from src.datamodule import get_transforms, get_loaders\n",
    "from src.model import make_model, PetMoodClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory\n",
    "data_dir = '../data/master_folder'\n",
    "\n",
    "# Get data loaders\n",
    "dataloaders = get_loaders(\n",
    "    data_dir=data_dir,\n",
    "    batch_size=32,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class names and dataset sizes\n",
    "class_names = dataloaders['train'].dataset.classes\n",
    "dataset_sizes = {x: len(dataloaders[x].dataset) for x in ['train', 'val', 'test']}\n",
    "\n",
    "print(f\"Classes: {class_names}\")\n",
    "print(f\"Dataset sizes: {dataset_sizes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some sample images\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Display image for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs[:16])\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "imshow(out, title=[class_names[x] for x in classes[:16]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "num_classes = len(class_names)\n",
    "backbone = 'resnet18'  # 'resnet18' or 'mobilenet_v2'\n",
    "\n",
    "model = PetMoodClassifier(\n",
    "    num_classes=num_classes,\n",
    "    backbone=backbone,\n",
    "    pretrained=True\n",
    ").to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function, optimizer and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-4)\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "\n",
    "# TensorBoard setup\n",
    "from datetime import datetime\n",
    "log_dir = os.path.join(\"../runs\", datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "print(f\"TensorBoard log directory: {log_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, scheduler, writer, num_epochs=15):\n",
    "    since = time.time()\n",
    "    \n",
    "    # Create models directory if it doesn't exist\n",
    "    os.makedirs('../models', exist_ok=True)\n",
    "    \n",
    "    # Initialize best model tracking\n",
    "    best_model_weights = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    # Track metrics\n",
    "    history = {\n",
    "        'train_loss': [], 'val_loss': [],\n",
    "        'train_acc': [], 'val_acc': []\n",
    "    }\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            # Iterate over data\n",
    "            pbar = tqdm(dataloaders[phase], desc=f\"{phase}\")\n",
    "            for inputs, labels in pbar:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Forward\n",
    "                # Track history only in train phase\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    # Backward + optimize only in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                # Update progress bar\n",
    "                pbar.set_postfix({\"loss\": loss.item()})\n",
    "            \n",
    "            # Compute epoch metrics\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            \n",
    "            # Update history\n",
    "            history[f'{phase}_loss'].append(epoch_loss)\n",
    "            history[f'{phase}_acc'].append(epoch_acc.item())\n",
    "            \n",
    "            # Log to tensorboard\n",
    "            writer.add_scalar(f'Loss/{phase}', epoch_loss, epoch)\n",
    "            writer.add_scalar(f'Accuracy/{phase}', epoch_acc, epoch)\n",
    "            \n",
    "            print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "            \n",
    "            # Save best model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_weights = copy.deepcopy(model.state_dict())\n",
    "                # Save best model\n",
    "                torch.save(model.state_dict(), f\"../models/best_model_notebook.pth\")\n",
    "                print(f\"Saved new best model with accuracy: {best_acc:.4f}\")\n",
    "        \n",
    "        # Step the scheduler\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:.4f}')\n",
    "    \n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_weights)\n",
    "    \n",
    "    # Return model and history\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model, history = train_model(\n",
    "    model=model,\n",
    "    dataloaders=dataloaders,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    writer=writer,\n",
    "    num_epochs=15\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_loss'], label='Training Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss vs. Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_acc'], label='Training Accuracy')\n",
    "plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "plt.title('Accuracy vs. Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../models/training_curves_notebook.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "def evaluate_model(model, dataloader, criterion, class_names):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # Iterate over data\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            # Save predictions and labels\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Compute metrics\n",
    "    test_loss = running_loss / len(dataloader.dataset)\n",
    "    test_acc = running_corrects.double() / len(dataloader.dataset)\n",
    "    \n",
    "    print(f'Test Loss: {test_loss:.4f} Acc: {test_acc:.4f}')\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    from sklearn.metrics import confusion_matrix, classification_report\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    \n",
    "    # Add text annotations to the confusion matrix\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                    horizontalalignment=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"../models/confusion_matrix.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Print classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "    \n",
    "    return test_acc, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_acc, confusion = evaluate_model(model, dataloaders['test'], criterion, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model\n",
    "model.save(f\"../models/final_model_notebook.pth\")\n",
    "print(f\"Model saved to ../models/final_model_notebook.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test on Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import prediction functions\n",
    "sys.path.append('..')\n",
    "from src.predict import predict_image, visualize_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a few sample images\n",
    "import glob\n",
    "\n",
    "# Get a few test images from each class\n",
    "test_images = []\n",
    "for cls in class_names:\n",
    "    cls_path = os.path.join(data_dir, 'test', cls.lower())\n",
    "    if os.path.exists(cls_path):\n",
    "        images = glob.glob(os.path.join(cls_path, '*.jpg'))[:2]  # Get 2 images per class\n",
    "        test_images.extend(images)\n",
    "    else:\n",
    "        print(f\"Warning: Path not found: {cls_path}\")\n",
    "\n",
    "# Test each image\n",
    "for img_path in test_images:\n",
    "    result = predict_image(img_path, model, device, class_names=class_names)\n",
    "    visualize_prediction(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "\n",
    "The notebook demonstrates the complete workflow for training and evaluating the Pet Mood Detector model. The model can now be used for inference on new images or through the webcam interface.\n",
    "\n",
    "To run inference on new images or using the webcam, you can use the command-line interface:\n",
    "\n",
    "```bash\n",
    "# For a single image\n",
    "python src/predict.py --image path/to/image.jpg --model models/final_model_notebook.pth\n",
    "\n",
    "# For webcam\n",
    "python src/predict.py --webcam --model models/final_model_notebook.pth\n",
    "```\n",
    "\n",
    "Or you can use the Gradio web interface:\n",
    "\n",
    "```bash\n",
    "python ui/app.py\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
